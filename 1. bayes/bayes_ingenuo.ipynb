{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes ingenuo tarea\n",
    "\n",
    "Este programa clasifica correos electrónicos como spam o ham utilizando el alrogítmo de bayes ingenuo. Cómo tarea quedó agregar el entrenamiento con una tercera clase. Este documento es el entregable del equipo 7: Alan Almora y Samuel Leidenberger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "usePackage <- function(p) \n",
    "{\n",
    "  if (!is.element(p, installed.packages()[,1]))\n",
    "    install.packages(p, repos = \"https://cran.itam.mx/\")\n",
    "  suppressPackageStartupMessages(require(p, character.only = TRUE, quietly  = TRUE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "usePackage('R.utils')\n",
    "usePackage('tm')\n",
    "usePackage('ramify')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "download.mails <- function(url, dir_name, file_name){\n",
    "\n",
    "  if (!file.exists(dir_name)) {\n",
    "    dir.create(dir_name)  \n",
    "  }\n",
    "  \n",
    "  download.file(url, destfile=file.path(dir_name, paste0(file_name,\".tar.bz2\")) )\n",
    "  bunzip2(file.path(dir_name, paste0(file_name,\".tar.bz2\")))\n",
    "  \n",
    "  untar(file.path(dir_name, paste0(file_name,\".tar\")), exdir = dir_name)\n",
    "  \n",
    "  if (file.exists(file.path(dir_name, paste0(file_name,\".tar\")))) {\n",
    "    file.remove(file.path(dir_name, paste0(file_name,\".tar\")))\n",
    "  }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_name <- \"data\"\n",
    "file_name <- \"easy_ham_2\"\n",
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham_2.tar.bz2\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_hard_ham.tar.bz2\"\n",
    "file_name <- \"hard_ham\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url <- \"http://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2\"\n",
    "file_name <- \"spam_2\"\n",
    "\n",
    "download.mails(url, dir_name, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los correos electrónicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una función que leea el mensaje del archivo que se le pase como parámetro\n",
    "# asumimos que el archivo contiene un correo\n",
    "\n",
    "lee_mensaje <- function(correo) {\n",
    "  fd <- file(correo, open = \"rt\")\n",
    "  lineas <- readLines(fd, warn=FALSE)\n",
    "  close(fd)\n",
    "  mensaje <- lineas[seq(which(lineas == \"\")[1] + 1, length(lineas), 1)]\n",
    "  return (paste(mensaje, collapse = \"\\n\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos variables con los directorios donde se encuentran los datos\n",
    "trayectoria_spam     <- file.path(dir_name, \"spam_2\")\n",
    "trayectoria_easyham  <- file.path(dir_name, \"easy_ham_2\")\n",
    "trayectoria_hardham  <- file.path(dir_name, \"hard_ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como spam\n",
    "archivos_correos_spam <- dir(trayectoria_spam)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_spam <- archivos_correos_spam[which(archivos_correos_spam!=\"cmds\")] #[1:250]\n",
    "\n",
    "archivos_correos_spam <- archivos_correos_spam[sample(1:length(archivos_correos_spam))]\n",
    "archivos_correos_spam_training <- archivos_correos_spam[1:201]\n",
    "archivos_correos_spam_testing <- archivos_correos_spam[201:250]\n",
    "\n",
    "todo_spam <- sapply(archivos_correos_spam_training,\n",
    "                   function(p) lee_mensaje(file.path(trayectoria_spam, p)))\n",
    "                    \n",
    "todo_spam <- enc2utf8(todo_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como ham fácilmente identificables\n",
    "archivos_correos_easy_ham <- dir(trayectoria_easyham)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_easy_ham <- archivos_correos_easy_ham[which(archivos_correos_easy_ham!=\"cmds\")] #[1:250]\n",
    "\n",
    "archivos_correos_easy_ham <- archivos_correos_easy_ham[sample(1:length(archivos_correos_easy_ham))]\n",
    "archivos_correos_easy_ham_training <- archivos_correos_easy_ham[1:201]\n",
    "archivos_correos_easy_ham_testing <- archivos_correos_easy_ham[201:250]\n",
    "\n",
    "todo_easy_ham <- sapply(archivos_correos_easy_ham_training,\n",
    "                    function(p) lee_mensaje(file.path(trayectoria_easyham, p)))\n",
    "\n",
    "todo_easy_ham <- enc2utf8(todo_easy_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el directorio donde se encuentran los correos clasificados como ham fácilmente identificables\n",
    "archivos_correos_hard_ham <- dir(trayectoria_hardham)\n",
    "\n",
    "# quitamos el guión llamado cmds\n",
    "archivos_correos_hard_ham <- archivos_correos_hard_ham[which(archivos_correos_hard_ham!=\"cmds\")] #[1:250]\n",
    "\n",
    "archivos_correos_hard_ham <- archivos_correos_hard_ham[sample(1:length(archivos_correos_hard_ham))]\n",
    "archivos_correos_hard_ham_training <- archivos_correos_hard_ham[1:201]\n",
    "archivos_correos_hard_ham_testing <- archivos_correos_hard_ham[201:250]\n",
    "\n",
    "todo_hard_ham <- sapply(archivos_correos_hard_ham_training,\n",
    "                    function(p) lee_mensaje(file.path(trayectoria_hardham, p)))\n",
    "\n",
    "todo_hard_ham <- enc2utf8(todo_hard_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de corpus y bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "obtiene_TermDocumentMatrix <- function (vector_correos) {\n",
    "  control <- list(stopwords = TRUE,\n",
    "                removePunctuation = TRUE,\n",
    "                removeNumbers = TRUE,\n",
    "                minDocFreq = 2)\n",
    "  corpus <- Corpus(VectorSource(vector_correos))\n",
    "  return(TermDocumentMatrix(corpus, control))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_TDM <- obtiene_TermDocumentMatrix(todo_spam)\n",
    "\n",
    "# Crea un data frame que provee el conjunto de caracteristicas de los datos de entrenamiento SPAM\n",
    "matriz_spam <- as.matrix(spam_TDM)\n",
    "\n",
    "conteos_spam <- rowSums(matriz_spam)\n",
    "df_spam <- data.frame(cbind(names(conteos_spam),\n",
    "                            as.numeric(conteos_spam)),\n",
    "                      stringsAsFactors = FALSE)\n",
    "names(df_spam) <- c(\"terminos\", \"frecuencia\")\n",
    "df_spam$frecuencia <- as.numeric(df_spam$frecuencia)\n",
    "ocurrencias_spam <- sapply(1:nrow(matriz_spam),\n",
    "                          function(i) # Obtiene la proporcion de documentos que contiene cada palabra\n",
    "                          {\n",
    "                            length(which(matriz_spam[i, ] > 0)) / ncol(matriz_spam)\n",
    "                          })\n",
    "densidad_spam <- df_spam$frecuencia/sum(df_spam$frecuencia,na.rm = TRUE)\n",
    "\n",
    "df_spam <- transform(df_spam,\n",
    "                     densidad = densidad_spam,\n",
    "                     ocurrencias = ocurrencias_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>terminos</th><th scope=col>frecuencia</th><th scope=col>densidad</th><th scope=col>ocurrencias</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>auto         </td><td>  5          </td><td>9.687106e-05 </td><td>0.01990050   </td></tr>\n",
       "\t<tr><td>can          </td><td>265          </td><td>5.134166e-03 </td><td>0.40298507   </td></tr>\n",
       "\t<tr><td>cards        </td><td> 18          </td><td>3.487358e-04 </td><td>0.05970149   </td></tr>\n",
       "\t<tr><td>compete      </td><td>  6          </td><td>1.162453e-04 </td><td>0.02985075   </td></tr>\n",
       "\t<tr><td>consolidation</td><td>  9          </td><td>1.743679e-04 </td><td>0.02985075   </td></tr>\n",
       "\t<tr><td>consultation </td><td>  6          </td><td>1.162453e-04 </td><td>0.02487562   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " terminos & frecuencia & densidad & ocurrencias\\\\\n",
       "\\hline\n",
       "\t auto          &   5           & 9.687106e-05  & 0.01990050   \\\\\n",
       "\t can           & 265           & 5.134166e-03  & 0.40298507   \\\\\n",
       "\t cards         &  18           & 3.487358e-04  & 0.05970149   \\\\\n",
       "\t compete       &   6           & 1.162453e-04  & 0.02985075   \\\\\n",
       "\t consolidation &   9           & 1.743679e-04  & 0.02985075   \\\\\n",
       "\t consultation  &   6           & 1.162453e-04  & 0.02487562   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| terminos | frecuencia | densidad | ocurrencias |\n",
       "|---|---|---|---|\n",
       "| auto          |   5           | 9.687106e-05  | 0.01990050    |\n",
       "| can           | 265           | 5.134166e-03  | 0.40298507    |\n",
       "| cards         |  18           | 3.487358e-04  | 0.05970149    |\n",
       "| compete       |   6           | 1.162453e-04  | 0.02985075    |\n",
       "| consolidation |   9           | 1.743679e-04  | 0.02985075    |\n",
       "| consultation  |   6           | 1.162453e-04  | 0.02487562    |\n",
       "\n"
      ],
      "text/plain": [
       "  terminos      frecuencia densidad     ocurrencias\n",
       "1 auto            5        9.687106e-05 0.01990050 \n",
       "2 can           265        5.134166e-03 0.40298507 \n",
       "3 cards          18        3.487358e-04 0.05970149 \n",
       "4 compete         6        1.162453e-04 0.02985075 \n",
       "5 consolidation   9        1.743679e-04 0.02985075 \n",
       "6 consultation    6        1.162453e-04 0.02487562 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>terminos</th><th scope=col>frecuencia</th><th scope=col>densidad</th><th scope=col>ocurrencias</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>alexandre             </td><td>2                     </td><td>6.451821e-05          </td><td>0.009950249           </td></tr>\n",
       "\t<tr><td>angles                </td><td>4                     </td><td>1.290364e-04          </td><td>0.019900498           </td></tr>\n",
       "\t<tr><td>anglesaminvestmentscom</td><td>1                     </td><td>3.225911e-05          </td><td>0.004975124           </td></tr>\n",
       "\t<tr><td>arafat                </td><td>4                     </td><td>1.290364e-04          </td><td>0.019900498           </td></tr>\n",
       "\t<tr><td>audiofile             </td><td>1                     </td><td>3.225911e-05          </td><td>0.004975124           </td></tr>\n",
       "\t<tr><td>awful                 </td><td>2                     </td><td>6.451821e-05          </td><td>0.009950249           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " terminos & frecuencia & densidad & ocurrencias\\\\\n",
       "\\hline\n",
       "\t alexandre              & 2                      & 6.451821e-05           & 0.009950249           \\\\\n",
       "\t angles                 & 4                      & 1.290364e-04           & 0.019900498           \\\\\n",
       "\t anglesaminvestmentscom & 1                      & 3.225911e-05           & 0.004975124           \\\\\n",
       "\t arafat                 & 4                      & 1.290364e-04           & 0.019900498           \\\\\n",
       "\t audiofile              & 1                      & 3.225911e-05           & 0.004975124           \\\\\n",
       "\t awful                  & 2                      & 6.451821e-05           & 0.009950249           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| terminos | frecuencia | densidad | ocurrencias |\n",
       "|---|---|---|---|\n",
       "| alexandre              | 2                      | 6.451821e-05           | 0.009950249            |\n",
       "| angles                 | 4                      | 1.290364e-04           | 0.019900498            |\n",
       "| anglesaminvestmentscom | 1                      | 3.225911e-05           | 0.004975124            |\n",
       "| arafat                 | 4                      | 1.290364e-04           | 0.019900498            |\n",
       "| audiofile              | 1                      | 3.225911e-05           | 0.004975124            |\n",
       "| awful                  | 2                      | 6.451821e-05           | 0.009950249            |\n",
       "\n"
      ],
      "text/plain": [
       "  terminos               frecuencia densidad     ocurrencias\n",
       "1 alexandre              2          6.451821e-05 0.009950249\n",
       "2 angles                 4          1.290364e-04 0.019900498\n",
       "3 anglesaminvestmentscom 1          3.225911e-05 0.004975124\n",
       "4 arafat                 4          1.290364e-04 0.019900498\n",
       "5 audiofile              1          3.225911e-05 0.004975124\n",
       "6 awful                  2          6.451821e-05 0.009950249"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "easy_ham_TDM <- obtiene_TermDocumentMatrix(todo_easy_ham)\n",
    "\n",
    "# Crea un data frame que provee el conjunto de caracteristicas de los datos de entrenamiento easy ham\n",
    "matriz_easy_ham <- as.matrix(easy_ham_TDM)\n",
    "\n",
    "conteos_easy_ham <- rowSums(matriz_easy_ham)\n",
    "df_easy_ham <- data.frame(cbind(names(conteos_easy_ham),\n",
    "                            as.numeric(conteos_easy_ham)),\n",
    "                      stringsAsFactors = FALSE)\n",
    "names(df_easy_ham) <- c(\"terminos\", \"frecuencia\")\n",
    "df_easy_ham$frecuencia <- as.numeric(df_easy_ham$frecuencia)\n",
    "ocurrencias_easy_ham <- sapply(1:nrow(matriz_easy_ham),\n",
    "                           function(i) # Obtiene la proporcion de documentos que contiene cada palabra\n",
    "                           {\n",
    "                             length(which(matriz_easy_ham[i, ] > 0)) / ncol(matriz_easy_ham)\n",
    "                           })\n",
    "densidad_easy_ham <- df_easy_ham$frecuencia/sum(df_easy_ham$frecuencia,na.rm = TRUE)\n",
    "\n",
    "df_easy_ham <- transform(df_easy_ham,\n",
    "                     densidad = densidad_easy_ham,\n",
    "                     ocurrencias = ocurrencias_easy_ham)\n",
    "head(df_easy_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard ham\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>terminos</th><th scope=col>frecuencia</th><th scope=col>densidad</th><th scope=col>ocurrencias</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>address     </td><td> 257        </td><td>1.104066e-03</td><td>0.686567164 </td></tr>\n",
       "\t<tr><td>also        </td><td> 232        </td><td>9.966663e-04</td><td>0.517412935 </td></tr>\n",
       "\t<tr><td>alt         </td><td>1106        </td><td>4.751349e-03</td><td>0.328358209 </td></tr>\n",
       "\t<tr><td>aufontfont  </td><td>   8        </td><td>3.436780e-05</td><td>0.004975124 </td></tr>\n",
       "\t<tr><td>available   </td><td> 148        </td><td>6.358044e-04</td><td>0.318407960 </td></tr>\n",
       "\t<tr><td>availablebr </td><td>  13        </td><td>5.584768e-05</td><td>0.064676617 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " terminos & frecuencia & densidad & ocurrencias\\\\\n",
       "\\hline\n",
       "\t address      &  257         & 1.104066e-03 & 0.686567164 \\\\\n",
       "\t also         &  232         & 9.966663e-04 & 0.517412935 \\\\\n",
       "\t alt          & 1106         & 4.751349e-03 & 0.328358209 \\\\\n",
       "\t aufontfont   &    8         & 3.436780e-05 & 0.004975124 \\\\\n",
       "\t available    &  148         & 6.358044e-04 & 0.318407960 \\\\\n",
       "\t availablebr  &   13         & 5.584768e-05 & 0.064676617 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| terminos | frecuencia | densidad | ocurrencias |\n",
       "|---|---|---|---|\n",
       "| address      |  257         | 1.104066e-03 | 0.686567164  |\n",
       "| also         |  232         | 9.966663e-04 | 0.517412935  |\n",
       "| alt          | 1106         | 4.751349e-03 | 0.328358209  |\n",
       "| aufontfont   |    8         | 3.436780e-05 | 0.004975124  |\n",
       "| available    |  148         | 6.358044e-04 | 0.318407960  |\n",
       "| availablebr  |   13         | 5.584768e-05 | 0.064676617  |\n",
       "\n"
      ],
      "text/plain": [
       "  terminos    frecuencia densidad     ocurrencias\n",
       "1 address      257       1.104066e-03 0.686567164\n",
       "2 also         232       9.966663e-04 0.517412935\n",
       "3 alt         1106       4.751349e-03 0.328358209\n",
       "4 aufontfont     8       3.436780e-05 0.004975124\n",
       "5 available    148       6.358044e-04 0.318407960\n",
       "6 availablebr   13       5.584768e-05 0.064676617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hard_ham_TDM <- obtiene_TermDocumentMatrix(todo_hard_ham)\n",
    "\n",
    "# Crea un data frame que provee el conjunto de caracteristicas de los datos de entrenamiento hard ham\n",
    "matriz_hard_ham <- as.matrix(hard_ham_TDM)\n",
    "\n",
    "conteos_hard_ham <- rowSums(matriz_hard_ham)\n",
    "df_hard_ham <- data.frame(cbind(names(conteos_hard_ham),\n",
    "                            as.numeric(conteos_hard_ham)),\n",
    "                      stringsAsFactors = FALSE)\n",
    "names(df_hard_ham) <- c(\"terminos\", \"frecuencia\")\n",
    "df_hard_ham$frecuencia <- as.numeric(df_hard_ham$frecuencia)\n",
    "ocurrencias_hard_ham <- sapply(1:nrow(matriz_hard_ham),\n",
    "                           function(i) # Obtiene la proporcion de documentos que contiene cada palabra\n",
    "                           {\n",
    "                             length(which(matriz_hard_ham[i, ] > 0)) / ncol(matriz_hard_ham)\n",
    "                           })\n",
    "densidad_hard_ham <- df_hard_ham$frecuencia/sum(df_hard_ham$frecuencia,na.rm = TRUE)\n",
    "\n",
    "df_hard_ham <- transform(df_hard_ham,\n",
    "                     densidad = densidad_hard_ham,\n",
    "                     ocurrencias = ocurrencias_hard_ham)\n",
    "head(df_hard_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de probabilidad a posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_posteriori <- function(trayectoria, df_entrenamiento, a_priori = 0.5, c = 1e-6)\n",
    "{\n",
    "  mensaje <- lee_mensaje(trayectoria)\n",
    "  mensaje <- enc2utf8(mensaje)\n",
    "  mensaje_TDM <- obtiene_TermDocumentMatrix(mensaje)\n",
    "  conteos_mensaje <- rowSums(as.matrix(mensaje_TDM))\n",
    "\n",
    "  # Encuentra palabras en data frame de entrenamiento\n",
    "  mensaje_palabras_comunes <- intersect(names(conteos_mensaje), df_entrenamiento$terminos)\n",
    "  \n",
    "  # Ahora sólo aplicamos la clasificación Bayes ingenuo\n",
    "  if(length(mensaje_palabras_comunes) < 1)\n",
    "  {\n",
    "    #return(a_priori * c ^ (length(conteos_mensaje)))\n",
    "    return(log(a_priori) + (length(conteos_mensaje)) *log(c))\n",
    "  }\n",
    "  else\n",
    "  {\n",
    "    probabilidades_palabras_comunes <- df_entrenamiento$densidad[match(mensaje_palabras_comunes, df_entrenamiento$terminos)]\n",
    "    #return(a_priori * prod(probabilidades_palabras_comunes) * c ^ (length(conteos_mensaje) - length(mensaje_palabras_comunes)))\n",
    "    return(log(a_priori) + sum(log(probabilidades_palabras_comunes)) + log(c) * (length(conteos_mensaje) - length(mensaje_palabras_comunes)))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_clasifica<- function(trayectoria, archivos) {\n",
    "\n",
    "  hard_ham_spam_prueba <- sapply(archivos,\n",
    "                             function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_spam))\n",
    "  hard_ham_ham_prueba <- sapply(archivos,\n",
    "                            function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_easy_ham))\n",
    "  \n",
    "  return (ifelse(hard_ham_spam_prueba > hard_ham_ham_prueba,\n",
    "                        TRUE,\n",
    "                        FALSE))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_clasifica<- function(trayectoria, archivos) {\n",
    "\n",
    "  densidades_spam_prueba <- sapply(archivos,\n",
    "                             function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_spam))\n",
    "  densidades_easy_ham_prueba <- sapply(archivos,\n",
    "                            function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_easy_ham))\n",
    "  densidades_hard_ham_prueba <- sapply(archivos,\n",
    "                            function(p) a_posteriori(file.path(trayectoria, p), df_entrenamiento = df_hard_ham))\n",
    "                                       \n",
    "    matriz_densidades <- matrix(c(densidades_spam_prueba, densidades_easy_ham_prueba, densidades_hard_ham_prueba), ncol=3)\n",
    "    return(argmax(matriz_densidades,rows=TRUE))\n",
    "    \n",
    "         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_hard_ham_res <- bi_clasifica(trayectoria_hardham, archivos_correos_hard_ham_testing)\n",
    "bi_easy_ham_res <- bi_clasifica(trayectoria_easyham, archivos_correos_easy_ham_testing)\n",
    "bi_spam_res     <- bi_clasifica(trayectoria_spam,    archivos_correos_spam_testing)\n",
    "\n",
    "tri_hard_ham_res <- tri_clasifica(trayectoria_hardham, archivos_correos_hard_ham_testing)\n",
    "tri_easy_ham_res <- tri_clasifica(trayectoria_easyham, archivos_correos_easy_ham_testing)\n",
    "tri_spam_res     <- tri_clasifica(trayectoria_spam,    archivos_correos_spam_testing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dos clases (easy - spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bi_easy_ham_res\n",
       "FALSE \n",
       "   50 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "bi_spam_res\n",
       "FALSE  TRUE \n",
       "    5    45 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "bi_hard_ham_res\n",
       "FALSE  TRUE \n",
       "   25    25 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(bi_easy_ham_res)\n",
    "table(bi_spam_res)\n",
    "table(bi_hard_ham_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tres clases (spam - easy - hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tri_easy_ham_res\n",
       " 2  3 \n",
       "49  1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tri_spam_res\n",
       " 1  2  3 \n",
       "43  5  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tri_hard_ham_res\n",
       " 1  2  3 \n",
       " 3 11 36 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(tri_easy_ham_res)\n",
    "table(tri_spam_res)\n",
    "table(tri_hard_ham_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "### cambios en relación a la biclasificación\n",
    "\n",
    "1. easy ham - el modelo tiene misma efectividad en clasificar easy ham, curiosamente, a veces lo clasifica como hard ham esto se justifica con intersecciones atípicamente altas entre palabras de los mails.\n",
    "2. spam - el modelo sufre un poco en la clasificación de spam, igualmente dadas las intersecciones que cuenta con hard_ham.\n",
    "3. hard ham - claramente hay una mejoría en la clasificación de hard_ham, esto dado que logra compensar las intersecciones con spam gracias al entrenamiento con su mismo conjunto \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
